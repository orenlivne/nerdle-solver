{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50efce8c-517b-47ca-9d81-70d88cdb5a5c",
   "metadata": {},
   "source": [
    "# 7-Slot Nerdle Solver Test\n",
    "We prove (by brute-force) that you can always solve mini-Nerdle in at most $4$ guesses regardless of the starting expression, provided you use the optimal strategy. The worst start having repeating numbers and thus less information, e.g. `10-5=5`. The best start has all different numbers: `28/7=4`, which needs at most $3$ guesses and $2.65 \\pm 0.5$ guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce14177-17d6-4ba1-bdd4-74ae65e07847",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nerdle\n",
    "import score as s\n",
    "import generator\n",
    "from nerdle import Hint, NerdleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e772c55-2cd9-4034-9a40-da234e49e783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6661 (0.0%) completed\n",
      "333 / 6661 (5.0%) completed\n",
      "666 / 6661 (10.0%) completed\n",
      "999 / 6661 (15.0%) completed\n",
      "1332 / 6661 (20.0%) completed\n",
      "1665 / 6661 (25.0%) completed\n",
      "1998 / 6661 (30.0%) completed\n",
      "2331 / 6661 (35.0%) completed\n",
      "2664 / 6661 (40.0%) completed\n",
      "2997 / 6661 (45.0%) completed\n",
      "3330 / 6661 (50.0%) completed\n",
      "3663 / 6661 (55.0%) completed\n",
      "3996 / 6661 (60.0%) completed\n",
      "4329 / 6661 (65.0%) completed\n",
      "4662 / 6661 (70.0%) completed\n",
      "4995 / 6661 (75.0%) completed\n",
      "5328 / 6661 (80.0%) completed\n",
      "5661 / 6661 (85.0%) completed\n",
      "5994 / 6661 (90.0%) completed\n",
      "6327 / 6661 (95.0%) completed\n",
      "6660 / 6661 (100.0%) completed\n"
     ]
    }
   ],
   "source": [
    "# Mini-Nerdle.\n",
    "NUM_SLOTS = 7\n",
    "SCORE_DB_FILE = \"nerdle{}.db\".format(NUM_SLOTS) \n",
    "\n",
    "solver_data = nerdle.create_solver_data(NUM_SLOTS, SCORE_DB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3afd369f-ec7b-4851-a58c-fcb9c0392625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6661 6661\n",
      "98-4=94 9=8 6661\n",
      "7-8+7=6 7=- 6661\n",
      "75-3=72 7=5 6661\n",
      "8-2*1=6 8=- 6661\n",
      "51+5=56 5=1 6661\n",
      "83-2=81 8=3 6661\n",
      "23-20=3 2=3 6661\n",
      "68/1=68 6=8 6661\n",
      "9+5-9=5 9=+ 6661\n",
      "94/47=2 9=4 6661\n"
     ]
    }
   ],
   "source": [
    "d = solver_data.score_db\n",
    "print(len(d), len(solver_data.answers))\n",
    "for key in list(d.keys())[:10]:\n",
    "    print(key, \"\".join(map(str, key[0])) + \"=\" + str(key[1]), len(d[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49778b3a-6809-4c49-8926-5b625833606c",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc1fb9d8-2907-4eb3-8139-1fe65b874e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2082 ?-?--?- True\n"
     ]
    }
   ],
   "source": [
    "scorer = s.Scorer(NUM_SLOTS)\n",
    "score = scorer(\"1*1*6=6\", \"99/9=11\")\n",
    "print(score, \n",
    "      s.score_to_hint_string(score, NUM_SLOTS),\n",
    "      s.score_to_hints(score, NUM_SLOTS) == [Hint.MISPLACED, Hint.INCORRECT, Hint.MISPLACED, Hint.INCORRECT, Hint.INCORRECT, Hint.MISPLACED, Hint.INCORRECT]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07bb9112-773b-4de4-a876-bee818b125da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> guess 1+6-7=0\n",
      "score ?----?- 2050 answers 128\n",
      "--> guess 2*19=38\n",
      "score --?++-- 352 answers 1\n",
      "--> guess 99/9=11\n",
      "score +++++++ 5461 answers 1\n"
     ]
    }
   ],
   "source": [
    "# A good initial guess significantly reduces the number of answers. In this case, from\n",
    "# 206 to 10.\n",
    "guess_history, hint_history, answer_size_history =  nerdle.NerdleSolver(solver_data).solve(\"99/9=11\", initial_guess= \"1+6-7=0\", debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76723e-dedc-49a8-8287-ad95fc3ac621",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "This is a fast in-memory dict implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6179500f-b2fd-4115-8d22-1f41f3edae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.96 s, sys: 14.4 ms, total: 4.97 s\n",
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%time guess_history, hint_history, answer_size_history = nerdle.NerdleSolver(solver_data).solve(\"99/9=11\", initial_guess=\"1+6-7=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1298bec-fd16-46dd-8ddf-6571ee1c9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"99/9=11\"\n",
    "solver = nerdle.NerdleSolver(solver_data)\n",
    "for start in list(solver_data.answers)[:5]:\n",
    "    print(start)\n",
    "    %time solver.solve(answer, initial_guess=start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5156fa-001e-4a9a-8969-b1a8038c6438",
   "metadata": {},
   "source": [
    "## Initial Guess Optimization\n",
    "Assuming something with a lot of different numbers and operators is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cc0fe-b8fb-49c4-b950-b693f4f2af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = \"99/9=11\"\n",
    "# solutions = [nerdle.NerdleSolver(solver_data).solve(answer, initial_guess=start) \n",
    "#              for start in solver_data.answers]\n",
    "# n = np.array([len(solution[0]) for solution in solutions])\n",
    "# num_answers = len(solver_data.answers)\n",
    "# compression_ratio = num_answers / np.array([solution[2][0] for solution in solutions])\n",
    "# print(np.mean(compression_ratio), np.std(compression_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1175cfca-137b-4755-a29c-2c5964fe8b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1+6-7=0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m solutions \u001b[38;5;241m=\u001b[39m [nerdle\u001b[38;5;241m.\u001b[39mNerdleSolver(solver_data)\u001b[38;5;241m.\u001b[39msolve(answer, initial_guess\u001b[38;5;241m=\u001b[39mstart) \n\u001b[1;32m      3\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m solver_data\u001b[38;5;241m.\u001b[39manswers ]               \n\u001b[1;32m      4\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(solution[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m solutions])\n\u001b[1;32m      5\u001b[0m num_answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(solver_data\u001b[38;5;241m.\u001b[39manswers)\n",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1+6-7=0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m solutions \u001b[38;5;241m=\u001b[39m [\u001b[43mnerdle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNerdleSolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_guess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      3\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m solver_data\u001b[38;5;241m.\u001b[39manswers ]               \n\u001b[1;32m      4\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(solution[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m solutions])\n\u001b[1;32m      5\u001b[0m num_answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(solver_data\u001b[38;5;241m.\u001b[39manswers)\n",
      "File \u001b[0;32m~/oren/nerdle-solver/nerdle.py:201\u001b[0m, in \u001b[0;36mNerdleSolver.solve\u001b[0;34m(self, answer, max_guesses, initial_guess, debug)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_db \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# First guess: fetch restricted dictionary using a query on data to create 'score_db'.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39manswers_of_score(guess, answers, score)\n\u001b[0;32m--> 201\u001b[0m     score_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestrict_by_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Subsequent guesses: simple query into the dictionary 'score_db' to make it smaller.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     answers \u001b[38;5;241m=\u001b[39m {a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m answers \u001b[38;5;28;01mif\u001b[39;00m score_db[guess][a] \u001b[38;5;241m==\u001b[39m score}\n",
      "File \u001b[0;32m~/oren/nerdle-solver/nerdle.py:73\u001b[0m, in \u001b[0;36m_NerdleDataDict.restrict_by_answers\u001b[0;34m(self, answers)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestrict_by_answers\u001b[39m(\u001b[38;5;28mself\u001b[39m,  answers: Set[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     74\u001b[0m         guess: \u001b[38;5;28mdict\u001b[39m((answer, score) \u001b[38;5;28;01mfor\u001b[39;00m answer, score \u001b[38;5;129;01min\u001b[39;00m scores_by_answer_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m answers)\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m guess, scores_by_answer_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_db\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     76\u001b[0m     }\n",
      "File \u001b[0;32m~/oren/nerdle-solver/nerdle.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestrict_by_answers\u001b[39m(\u001b[38;5;28mself\u001b[39m,  answers: Set[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 74\u001b[0m         guess: \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscores_by_answer_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m guess, scores_by_answer_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_db\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     76\u001b[0m     }\n",
      "File \u001b[0;32m~/oren/nerdle-solver/nerdle.py:74\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestrict_by_answers\u001b[39m(\u001b[38;5;28mself\u001b[39m,  answers: Set[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 74\u001b[0m         guess: \u001b[38;5;28mdict\u001b[39m((answer, score) \u001b[38;5;28;01mfor\u001b[39;00m answer, score \u001b[38;5;129;01min\u001b[39;00m scores_by_answer_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m answers)\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m guess, scores_by_answer_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_db\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     76\u001b[0m     }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = \"1+6-7=0\"\n",
    "solutions = [nerdle.NerdleSolver(solver_data).solve(answer, initial_guess=start) \n",
    "             for answer in solver_data.answers]               \n",
    "n = np.array([len(solution[0]) for solution in solutions])\n",
    "num_answers = len(solver_data.answers)\n",
    "compression_ratio = num_answers / np.array([solution[2][0] for solution in solutions])\n",
    "print(np.mean(compression_ratio), np.std(compression_ratio))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.hist(n);\n",
    "ax.set_title(\"#Guesses for start {}\".format(start));\n",
    "\n",
    "ax = axs[1]\n",
    "ax.hist(compression_ratio);\n",
    "ax.set_title(\"Compression Ratio Distribution, start {}\".format(start));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d55266-8f90-4f1b-b63a-4cec52596d5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3066f7fc-2942-4182-b01c-7f5287f2e880",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_NerdleDataDict' object has no attribute 'score_db'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpstats\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SortKey\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcProfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mguess_history, hint_history, answer_size_history = nerdle.NerdleSolver(solver_data).solve(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m99/9=11\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, initial_guess=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1+6-7=0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, debug=True)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m p \u001b[38;5;241m=\u001b[39m pstats\u001b[38;5;241m.\u001b[39mStats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m p\u001b[38;5;241m.\u001b[39msort_stats(SortKey\u001b[38;5;241m.\u001b[39mCUMULATIVE)\u001b[38;5;241m.\u001b[39mprint_stats(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nerdle/lib/python3.10/cProfile.py:16\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(statement, filename, sort)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(statement, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pyprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Utils\u001b[49m\u001b[43m(\u001b[49m\u001b[43mProfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nerdle/lib/python3.10/profile.py:53\u001b[0m, in \u001b[0;36m_Utils.run\u001b[0;34m(self, statement, filename, sort)\u001b[0m\n\u001b[1;32m     51\u001b[0m prof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nerdle/lib/python3.10/cProfile.py:95\u001b[0m, in \u001b[0;36mProfile.run\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m __main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nerdle/lib/python3.10/cProfile.py:100\u001b[0m, in \u001b[0;36mProfile.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m~/oren/nerdle-solver/nerdle.py:134\u001b[0m, in \u001b[0;36mNerdleSolver.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# A working copy of data.score_db entries modified within solve().\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_db \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_db\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39manswers)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_answers)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_NerdleDataDict' object has no attribute 'score_db'"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "136422f3-02f5-45d8-ba29-66c2afd517b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> guess 1+6-7=0\n",
      "score ?----?- 2050 answers 128\n",
      "--> guess 2*19=38\n",
      "score --?++-- 352 answers 1\n",
      "--> guess 99/9=11\n",
      "score +++++++ 5461 answers 1\n",
      "Wed Sep 14 09:28:01 2022    stats\n",
      "\n",
      "         1039396 function calls (1039375 primitive calls) in 7.575 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 60 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    7.575    7.575 {built-in method builtins.exec}\n",
      "        1    0.001    0.001    7.575    7.575 <string>:1(<module>)\n",
      "        1    0.000    0.000    7.572    7.572 /Users/olivne/oren/nerdle-solver/nerdle.py:146(solve)\n",
      "        1    0.000    0.000    7.572    7.572 /Users/olivne/oren/nerdle-solver/nerdle.py:152(solve_adversary)\n",
      "        3    0.017    0.006    7.571    2.524 /Users/olivne/oren/nerdle-solver/nerdle.py:181(make_guess)\n",
      "        3    0.000    0.000    7.370    2.457 /Users/olivne/oren/nerdle-solver/nerdle.py:91(restrict_by_answers)\n",
      "        3    0.331    0.110    7.370    2.457 /Users/olivne/oren/nerdle-solver/nerdle.py:92(<dictcomp>)\n",
      "   885913    7.036    0.000    7.036    0.000 /Users/olivne/oren/nerdle-solver/nerdle.py:93(<genexpr>)\n",
      "        2    0.003    0.001    0.181    0.091 {built-in method builtins.min}\n",
      "    13324    0.020    0.000    0.179    0.000 /Users/olivne/oren/nerdle-solver/nerdle.py:193(<genexpr>)\n",
      "    13322    0.011    0.000    0.150    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/collections/__init__.py:565(__init__)\n",
      "    13322    0.008    0.000    0.139    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/collections/__init__.py:640(update)\n",
      "    13322    0.119    0.000    0.119    0.000 {built-in method _collections._count_elements}\n",
      "    13334    0.005    0.000    0.012    0.000 {built-in method builtins.isinstance}\n",
      "    13322    0.004    0.000    0.007    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/abc.py:117(__instancecheck__)\n",
      "    13322    0.006    0.000    0.006    0.000 {built-in method builtins.max}\n",
      "    13322    0.003    0.000    0.003    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    19988    0.003    0.000    0.003    0.000 {method 'items' of 'dict' objects}\n",
      "    26644    0.003    0.000    0.003    0.000 {method 'values' of 'dict' objects}\n",
      "        3    0.000    0.000    0.002    0.001 /Users/olivne/oren/nerdle-solver/nerdle.py:88(answers_of_score)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x277bceaa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cProfile.run('guess_history, hint_history, answer_size_history = nerdle.NerdleSolver(solver_data).solve(\"99/9=11\", initial_guess=\"1+6-7=0\", debug=True)', 'stats')\n",
    "p = pstats.Stats('stats')\n",
    "p.sort_stats(SortKey.CUMULATIVE).print_stats(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cba035a9-16e1-4a13-bec3-5df0d55606b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000 (0.0%) completed\n",
      "50 / 1000 (5.0%) completed\n",
      "100 / 1000 (10.0%) completed\n",
      "150 / 1000 (15.0%) completed\n",
      "200 / 1000 (20.0%) completed\n",
      "250 / 1000 (25.0%) completed\n",
      "300 / 1000 (30.0%) completed\n",
      "350 / 1000 (35.0%) completed\n",
      "400 / 1000 (40.0%) completed\n",
      "450 / 1000 (45.0%) completed\n",
      "500 / 1000 (50.0%) completed\n",
      "550 / 1000 (55.0%) completed\n",
      "600 / 1000 (60.0%) completed\n",
      "650 / 1000 (65.0%) completed\n",
      "700 / 1000 (70.0%) completed\n",
      "750 / 1000 (75.0%) completed\n",
      "800 / 1000 (80.0%) completed\n",
      "850 / 1000 (85.0%) completed\n",
      "900 / 1000 (90.0%) completed\n",
      "950 / 1000 (95.0%) completed\n",
      "Wed Sep 14 09:29:42 2022    stats\n",
      "\n",
      "         2830597 function calls in 4.903 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 46 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    4.941    4.941 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    4.923    4.923 /Users/olivne/oren/nerdle-solver/nerdle.py:207(create_solver_data)\n",
      "        1    0.003    0.003    4.923    4.923 /Users/olivne/oren/nerdle-solver/nerdle.py:54(__init__)\n",
      "        1    0.002    0.002    4.056    4.056 /Users/olivne/oren/nerdle-solver/nerdle.py:67(_create_score_database)\n",
      "     1000    0.306    0.000    4.051    0.004 /Users/olivne/oren/nerdle-solver/nerdle.py:78(<dictcomp>)\n",
      "  1000000    3.551    0.000    3.745    0.000 /Users/olivne/oren/nerdle-solver/score.py:29(__call__)\n",
      "     6662    0.096    0.000    0.820    0.000 /Users/olivne/oren/nerdle-solver/generator.py:9(all_answers)\n",
      "   115668    0.644    0.000    0.664    0.000 {built-in method builtins.eval}\n",
      "  1544712    0.194    0.000    0.194    0.000 {method 'remove' of 'list' objects}\n",
      "   115668    0.053    0.000    0.053    0.000 {method 'join' of 'str' objects}\n",
      "        1    0.043    0.043    0.043    0.043 {built-in method _pickle.dump}\n",
      "    25856    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "       20    0.000    0.000    0.003    0.000 {built-in method builtins.print}\n",
      "       40    0.000    0.000    0.003    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/site-packages/ipykernel/iostream.py:518(write)\n",
      "    20515    0.002    0.000    0.002    0.000 {method 'is_integer' of 'float' objects}\n",
      "       40    0.000    0.000    0.002    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/site-packages/ipykernel/iostream.py:448(_schedule_flush)\n",
      "       10    0.000    0.000    0.002    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/site-packages/ipykernel/iostream.py:202(schedule)\n",
      "       10    0.002    0.000    0.002    0.000 /Users/olivne/opt/miniconda3/envs/nerdle/lib/python3.10/site-packages/zmq/sugar/socket.py:543(send)\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1cf7afd90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cProfile.run('solver_data = nerdle.create_solver_data(7, \"nerdle7_test.db\", overwrite=True, max_answers=1000)', 'stats')\n",
    "p = pstats.Stats('stats')\n",
    "p.sort_stats(SortKey.CUMULATIVE).print_stats(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4658070b-abb4-4c46-942e-22c74dcaabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 14 09:55:45 2022    stats\n",
      "\n",
      "         200003 function calls in 0.535 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.535    0.535 {built-in method builtins.exec}\n",
      "        1    0.041    0.041    0.534    0.534 <string>:1(<module>)\n",
      "   200000    0.493    0.000    0.493    0.000 {score_guess.score_guess}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x222c07760>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import score_guess as sg\n",
    "cProfile.run('for _ in range(200000): sg.score_guess(\"1*1*6=6\", \"99/9=11\")', 'stats')\n",
    "p = pstats.Stats('stats')\n",
    "p.sort_stats(SortKey.CUMULATIVE).print_stats(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab634ba-0bba-4915-a52a-988899d64f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
